{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea89cde4",
   "metadata": {},
   "source": [
    "# Facial Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d637f92",
   "metadata": {},
   "source": [
    "#### Table of Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b138b9",
   "metadata": {},
   "source": [
    "1. [Library Imports](#Library-Imports)\n",
    "2. [Data Reading & Splitting](#Data-Reading-and-Splitting)\n",
    "3. [Data Visualization](#Data-Visualization)\n",
    "4. [Exploratory Data Analysis](#EDA)\n",
    "5. [Data Augmentation](#Data-Augmentation)\n",
    "6. [Model Metrics](#Model-Metrics)\n",
    "7. [Model Training](#Model-Training)\n",
    " - [Logistic Regression Baseline](#Logistic-Regression-Baseline)\n",
    " - [Simple Neural Network Baseline](#Simple-Neural-Network-Baseline)\n",
    " - [Simple Convolutional Neural Network Baseline](#Simple-Convolutional-Neural-Network-Baseline)\n",
    " - [Convolutional Neural Network](#Convolutional-Neural-Network-Model)\n",
    " - [Transfer Learning](#Transfer-Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f667a",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968961aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import regularizers as reg\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten, GlobalAveragePooling2D, InputLayer, Dropout, SpatialDropout2D, BatchNormalization, Resizing, Rescaling, RandomFlip, RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4c92bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec748acd",
   "metadata": {},
   "source": [
    "### Data Reading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509eefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# defining dir variables \n",
    "root_dir = 'Data/'\n",
    "train_dir = root_dir + 'train/'\n",
    "valid_dir = root_dir + 'valid/'\n",
    "test_dir = root_dir + 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8f4b4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-15c692331f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m train_data = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/preprocessing/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m   image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    191\u001b[0m       \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/preprocessing/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0msubdirs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/train/'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "valid_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    valid_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbdaff9",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.class_names\n",
    "num_classes = len(class_names)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258eca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = os.listdir(valid_dir)\n",
    "target_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9822dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_data.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36494b02",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6759fab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac6e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff35d9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de84576d",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718997ad",
   "metadata": {},
   "source": [
    "- Resize the images (180x180)\n",
    "- Scaling/Normalization (1 to 255)\n",
    "- Randomly flip images (Horizontally)\n",
    "- Randomly rotate images (up to 20Â°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential([\n",
    "    Resizing(48, 48),\n",
    "    Rescaling(1./255),\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582815b",
   "metadata": {},
   "source": [
    "### Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d897af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_performance(hist, model_name=None, save=False):\n",
    "    model_hist = pd.DataFrame(hist.history)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.lineplot(data=model_hist[['accuracy', 'val_accuracy']])\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    \n",
    "    if save and model_name:\n",
    "        plt.title(f'{model_name} Accuracy Graph')\n",
    "        plt.savefig(f'Images/{model_name} accuracy graph.png', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895490a",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3883688",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_data = test_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cfc310",
   "metadata": {},
   "source": [
    "##### Simple Neural Network Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644eabf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbase_NN = Sequential()\n",
    "sbase_NN.add(data_augmentation)\n",
    "sbase_NN.add(Dense(8, activation='relu'))\n",
    "sbase_NN.add(Flatten())\n",
    "sbase_NN.add(Dense(7, activation='softmax'))\n",
    "sbase_NN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a770bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbase_NN_hist = sbase_NN.fit(train_data, epochs=4, validation_data=valid_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733be699",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(sbase_NN_hist,'Simple Baseline NN', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = sbase_NN.evaluate(train_data, verbose=1)\n",
    "valid_loss, valid_acc = sbase_NN.evaluate(valid_data, verbose=1)\n",
    "\n",
    "print(f'\\n\\nTraining Accuracy:\\t{train_acc * 100}\\nTraining Loss:\\t\\t{train_loss}\\n')\n",
    "print(f'Validation Accuracy:\\t{valid_acc * 100}\\nValidation Loss:\\t{valid_loss}\\n')\n",
    "print('Train/Validation Diff:\\t', (train_acc - valid_acc) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0052a8b",
   "metadata": {},
   "source": [
    "##### Neural Network Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7c9e25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_augmentation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9071d633149f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbase_NN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbase_NN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_augmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbase_NN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase_NN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbase_NN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_augmentation' is not defined"
     ]
    }
   ],
   "source": [
    "base_NN = Sequential()\n",
    "base_NN.add(data_augmentation)\n",
    "base_NN.add(Dense(4, activation='relu'))\n",
    "base_NN.add(Dense(8, activation='relu'))\n",
    "base_NN.add(Dense(16,activation='relu'))\n",
    "base_NN.add(Dense(32,activation='relu'))\n",
    "base_NN.add(Dense(16,activation='relu'))\n",
    "base_NN.add(Dense(8, activation='relu'))\n",
    "base_NN.add(Flatten())\n",
    "base_NN.add(Dense(7, activation='softmax'))\n",
    "\n",
    "base_NN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2d2f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-21cdb2150a37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_NN_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_NN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "base_NN_hist = base_NN.fit(train_data, epochs=6, validation_data=valid_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99852a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_model_performance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6b137d5b6316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_NN_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Baseline NN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_model_performance' is not defined"
     ]
    }
   ],
   "source": [
    "plot_model_performance(base_NN_hist, 'Baseline NN', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b99a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718/718 [==============================] - 48s 67ms/step - loss: 1.7527 - accuracy: 0.2664\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 1.7599 - accuracy: 0.2617\n",
      "\n",
      "\n",
      "Training Accuracy:\t26.6440212726593\n",
      "Training Loss:\t\t1.752709150314331\n",
      "\n",
      "Validation Accuracy:\t26.1701762676239\n",
      "Validation Loss:\t1.7598847150802612\n",
      "\n",
      "Train/Validation Diff:\t 0.4738450050354004\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = base_NN.evaluate(train_data, verbose=1)\n",
    "valid_loss, valid_acc = base_NN.evaluate(valid_data, verbose=1)\n",
    "\n",
    "print(f'\\n\\nTraining Accuracy:\\t{train_acc * 100}\\nTraining Loss:\\t\\t{train_loss}\\n')\n",
    "print(f'Validation Accuracy:\\t{valid_acc * 100}\\nValidation Loss:\\t{valid_loss}\\n')\n",
    "print('Train/Validation Diff:\\t', (train_acc - valid_acc) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59108ac7",
   "metadata": {},
   "source": [
    "##### Simple Convolutional Neural Network Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "243fe972",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_CNN = Sequential()\n",
    "base_CNN.add(data_augmentation)\n",
    "base_CNN.add(Conv2D(filters=10, kernel_size=3, activation='relu', padding='same'))\n",
    "base_CNN.add(MaxPooling2D())\n",
    "base_CNN.add(Conv2D(filters=5, kernel_size=3, activation='relu', padding='same'))\n",
    "base_CNN.add(MaxPooling2D())\n",
    "base_CNN.add(Flatten())\n",
    "base_CNN.add(Dense(7, activation='softmax'))\n",
    "base_CNN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b979dd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "718/718 [==============================] - 46s 63ms/step - loss: 1.7983 - accuracy: 0.2564 - val_loss: 1.7633 - val_accuracy: 0.2666\n",
      "Epoch 2/5\n",
      "718/718 [==============================] - 81s 113ms/step - loss: 1.7615 - accuracy: 0.2700 - val_loss: 1.7424 - val_accuracy: 0.2748\n",
      "Epoch 3/5\n",
      "718/718 [==============================] - 81s 112ms/step - loss: 1.7377 - accuracy: 0.2878 - val_loss: 1.7267 - val_accuracy: 0.2995\n",
      "Epoch 4/5\n",
      "718/718 [==============================] - 66s 92ms/step - loss: 1.7230 - accuracy: 0.3045 - val_loss: 1.6987 - val_accuracy: 0.3106\n",
      "Epoch 5/5\n",
      "718/718 [==============================] - 73s 101ms/step - loss: 1.7082 - accuracy: 0.3133 - val_loss: 1.6876 - val_accuracy: 0.3188\n"
     ]
    }
   ],
   "source": [
    "base_CNN_hist = base_CNN.fit(train_data, epochs=5, validation_data=valid_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4404785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_performance(base_CNN_hist, 'Baseline CNN', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9fb83eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718/718 [==============================] - 62s 87ms/step - loss: 1.6738 - accuracy: 0.3318\n",
      "180/180 [==============================] - 13s 72ms/step - loss: 1.6876 - accuracy: 0.3188\n",
      "\n",
      "\n",
      "Training Accuracy:\t33.17655324935913\n",
      "Training Loss:\t\t1.6737563610076904\n",
      "\n",
      "Validation Accuracy:\t31.87749981880188\n",
      "Validation Loss:\t1.6876177787780762\n",
      "\n",
      "Train/Validation Diff:\t 1.299053430557251\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = base_CNN.evaluate(train_data, verbose=1)\n",
    "valid_loss, valid_acc = base_CNN.evaluate(valid_data, verbose=1)\n",
    "\n",
    "print(f'\\n\\nTraining Accuracy:\\t{train_acc * 100}\\nTraining Loss:\\t\\t{train_loss}\\n')\n",
    "print(f'Validation Accuracy:\\t{valid_acc * 100}\\nValidation Loss:\\t{valid_loss}\\n')\n",
    "print('Train/Validation Diff:\\t', (train_acc - valid_acc) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd118280",
   "metadata": {},
   "source": [
    "##### Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b556314",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_opt = SGD(learning_rate=0.001) \n",
    "adam_opt = Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = Sequential()\n",
    "\n",
    "CNN.add(data_augmentation)\n",
    "\n",
    "CNN.add(Conv2D(filters=32, strides=2, kernel_size=3, kernel_regularizer=reg.L2(), activation='relu', padding='same'))\n",
    "CNN.add(SpatialDropout2D(0.4))\n",
    "CNN.add(BatchNormalization())\n",
    "CNN.add(Conv2D(filters=32, strides=2, kernel_size=3, kernel_regularizer=reg.L2(), activation='relu', padding='same'))\n",
    "CNN.add(SpatialDropout2D(0.4))\n",
    "CNN.add(BatchNormalization())\n",
    "\n",
    "CNN.add(Conv2D(filters=64, strides=2, kernel_size=3, kernel_regularizer=reg.L2(), activation='relu', padding='same'))\n",
    "CNN.add(SpatialDropout2D(0.4))\n",
    "CNN.add(BatchNormalization())\n",
    "CNN.add(Conv2D(filters=64, strides=2, kernel_size=3, kernel_regularizer=reg.L2(), activation='relu', padding='same'))\n",
    "CNN.add(SpatialDropout2D(0.4))\n",
    "CNN.add(BatchNormalization())\n",
    "\n",
    "CNN.add(Conv2D(filters=128, strides=2, kernel_size=3, kernel_regularizer=reg.L2(), activation='relu', padding='same'))\n",
    "CNN.add(SpatialDropout2D(0.4))\n",
    "CNN.add(BatchNormalization())\n",
    "CNN.add(Conv2D(filters=128, strides=2, kernel_size=3, kernel_regularizer=reg.L2(), activation='relu', padding='same'))\n",
    "CNN.add(SpatialDropout2D(0.4))\n",
    "CNN.add(BatchNormalization())\n",
    "\n",
    "CNN.add(Conv2D(filters=256, strides=2, kernel_size=3, kernel_regularizer=reg.L2(), activation='relu', padding='same'))\n",
    "CNN.add(SpatialDropout2D(0.4))\n",
    "CNN.add(BatchNormalization())\n",
    "\n",
    "CNN.add(GlobalAveragePooling2D())\n",
    "\n",
    "CNN.add(Dense(7, activation='softmax'))\n",
    "\n",
    "CNN.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ab5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_hist = CNN.fit(train_data, epochs=300, validation_data=valid_data, verbose=1, callbacks=[keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=.25, patience=4, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9233778",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(CNN_hist, 'Convultional Neural Network', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7887b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = CNN.evaluate(train_data, verbose=1)\n",
    "valid_loss, valid_acc = CNN.evaluate(valid_data, verbose=1)\n",
    "\n",
    "print(f'\\n\\nTraining Accuracy:\\t{train_acc * 100}\\nTraining Loss:\\t\\t{train_loss}\\n')\n",
    "print(f'Validation Accuracy:\\t{valid_acc * 100}\\nValidation Loss:\\t{valid_loss}\\n')\n",
    "print('Train/Validation Diff:\\t', np.abs(train_acc - valid_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed602415",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.save('Deliverables/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210f461",
   "metadata": {},
   "source": [
    "##### Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2681615",
   "metadata": {},
   "source": [
    "Using DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b87f93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers\n",
    "dense_net = DenseNet169(weights='imagenet', include_top=False, input_shape=None)\n",
    "\n",
    "for layer in dense_net.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8870ba8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet169 (Functional)    (None, None, None, 1664)  12642880  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1664)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               426240    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,104,455\n",
      "Trainable params: 460,807\n",
      "Non-trainable params: 12,643,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_dense_transfer = Sequential()\n",
    "CNN_dense_transfer.add(dense_net)\n",
    "CNN_dense_transfer.add(GlobalAveragePooling2D())\n",
    "\n",
    "CNN_dense_transfer.add(Dense(256 , activation ='relu'))\n",
    "CNN_dense_transfer.add(BatchNormalization())\n",
    "CNN_dense_transfer.add(Dense(128 , activation ='relu'))\n",
    "CNN_dense_transfer.add(BatchNormalization())\n",
    "\n",
    "CNN_dense_transfer.add(Dense(7, activation='softmax'))\n",
    "\n",
    "CNN_dense_transfer.compile(loss='sparse_categorical_crossentropy', optimizer=sgd_opt, metrics = ['accuracy'])\n",
    "CNN_dense_transfer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577e254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "718/718 [==============================] - ETA: 0s - loss: 2.0322 - accuracy: 0.2231"
     ]
    }
   ],
   "source": [
    "CNN_dense_transfer_hist = CNN_dense_transfer.fit(train_data, epochs=10, validation_data=valid_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(CNN_dense_transfer_hist, 'Convultional Neural Network with DenseNet Transfer Learning', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a29e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = CNN_dense_transfer.evaluate(train_data, verbose=1)\n",
    "valid_loss, valid_acc = CNN_dense_transfer.evaluate(valid_data, verbose=1)\n",
    "\n",
    "print(f'\\n\\nTraining Accuracy:\\t{train_acc * 100}\\nTraining Loss:\\t\\t{train_loss}\\n')\n",
    "print(f'Validation Accuracy:\\t{valid_acc * 100}\\nValidation Loss:\\t{valid_loss}\\n')\n",
    "print('Train/Validation Diff:\\t', np.abs(train_acc - valid_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901cda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(CNN_dense_transfer, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589cdc5",
   "metadata": {},
   "source": [
    "Using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=None)\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16_transfer = Sequential()\n",
    "\n",
    "vgg_16_transfer.add(data_augmentation)\n",
    "\n",
    "vgg_16_transfer.add(vgg)\n",
    "\n",
    "vgg_16_transfer.add(GlobalAveragePooling2D()) # try it using max Pooling2\n",
    "\n",
    "vgg_16_transfer.add(Dense(200 , activation ='relu'))\n",
    "vgg_16_transfer.add(BatchNormalization())\n",
    "vgg_16_transfer.add(Dense(200 , activation ='relu'))\n",
    "vgg_16_transfer.add(BatchNormalization())\n",
    "vgg_16_transfer.add(Dense(200 , activation ='relu'))\n",
    "\n",
    "vgg_16_transfer.add(GlobalMaxPooling2D())\n",
    "vgg_16_transfer.add(Dense(7, activation='softmax'))\n",
    "\n",
    "vgg_16_transfer.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d18ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16_transfer = vgg_16_transfer.fit(train_data, epochs=15, validation_data=valid_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(vgg_16_transfer, 'Convultional Neural Network with VGG16 Transfer Learning', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eafcf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = vgg_16_transfer.evaluate(train_data, verbose=1)\n",
    "valid_loss, valid_acc = vgg_16_transfer.evaluate(valid_data, verbose=1)\n",
    "\n",
    "print(f'\\n\\nTraining Accuracy:\\t{train_acc * 100}\\nTraining Loss:\\t\\t{train_loss}\\n')\n",
    "print(f'Validation Accuracy:\\t{valid_acc * 100}\\nValidation Loss:\\t{valid_loss}\\n')\n",
    "print('Train/Validation Diff:\\t', np.abs(train_acc - valid_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vgg_16_transfer, open('vgg_16_transfer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7aeab",
   "metadata": {},
   "source": [
    "Using VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12eaa473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "73703424/80134624 [==========================>...] - ETA: 2s"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2e8f548bedc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg_19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvgg_19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/applications/vgg19.py\u001b[0m in \u001b[0;36mVGG19\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    220\u001b[0m           file_hash='cbe5617147190e668d6c5d5026f83318')\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m       weights_path = data_utils.get_file(\n\u001b[0m\u001b[1;32m    223\u001b[0m           \u001b[0;34m'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m           \u001b[0mWEIGHTS_PATH_NO_TOP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlretrieve\u001b[0m  \u001b[0;31m# pylint: disable=g-importing-member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "vgg_19 = VGG19(weights='imagenet', include_top=False, input_shape=None)\n",
    "\n",
    "for layer in vgg_19.layers[:-2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46aafa0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5d6d1bfeb0ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg_19_transfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvgg_19_transfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvgg_19_transfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_augmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvgg_19_transfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "vgg_19_transfer = Sequential()\n",
    "vgg_19_transfer.add(Dropout(0.2)) # dropout\n",
    "vgg_19_transfer.add(data_augmentation)\n",
    "\n",
    "vgg_19_transfer.add(vgg_19)\n",
    "\n",
    "vgg_19_transfer.add(GlobalAveragePooling2D())\n",
    "\n",
    "vgg_19_transfer.add(Dense(200 , activation ='relu', kernel_regularizer=regularizers.l2(0.01))) # , kernel_regularizer=regularizers.l2(0.01)\n",
    "vgg_19_transfer.add(BatchNormalization()) \n",
    "vgg_19_transfer.add(Dense(100 , activation ='relu'))\n",
    "\n",
    "vgg_19_transfer.add(BatchNormalization())\n",
    "vgg_19_transfer.add(Dense(50 , activation ='relu'))\n",
    "vgg_19_transfer.add(BatchNormalization())\n",
    "vgg_19_transfer.add(Dense(7, activation='softmax'))\n",
    "\n",
    "vgg_19_transfer.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3553290",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_19_transfer_hist = vgg_19_transfer.fit(train_data, epochs=10, validation_data=valid_data, verbose=1,callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=8, verbose=1, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=.5, patience=3, verbose=1),\n",
    "    ])\n",
    "\n",
    "'''\n",
    ",callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=8, verbose=1, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=.5, patience=3, verbose=1),\n",
    "    ]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(vgg_19_transfer_hist, 'Convultional Neural Network with VGG19 Transfer Learning', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = vgg_19_transfer.evaluate(train_data, verbose=1)\n",
    "valid_loss, valid_acc = vgg_19_transfer.evaluate(valid_data, verbose=1)\n",
    "\n",
    "print(f'\\n\\nTraining Accuracy:\\t{train_acc * 100}\\nTraining Loss:\\t\\t{train_loss}\\n')\n",
    "print(f'Validation Accuracy:\\t{valid_acc * 100}\\nValidation Loss:\\t{valid_loss}\\n')\n",
    "print('Train/Validation Diff:\\t', np.abs(train_acc - valid_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vgg_19_transfer, open('vgg_19_transfer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4132ea07",
   "metadata": {},
   "source": [
    "Using InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00370da",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3 = InceptionV3(weights='imagenet', include_top=False, input_shape=None)\n",
    "\n",
    "for layer in inception_v3.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_transfer = Sequential()\n",
    "\n",
    "vgg_19_transfer.add(Dropout(0.2)) # dropout\n",
    "\n",
    "inception_transfer.add(data_augmentation)\n",
    "inception_transfer.add(inception_v3)\n",
    "inception_transfer.add(GlobalAveragePooling2D())\n",
    "\n",
    "inception_transfer.add(Dense(200 , activation ='relu'))\n",
    "inception_transfer.add(BatchNormalization())\n",
    "inception_transfer.add(Dense(100 , activation ='relu'))\n",
    "inception_transfer.add(BatchNormalization())\n",
    "inception_transfer.add(Dense(50 , activation ='relu'))\n",
    "inception_transfer.add(BatchNormalization())\n",
    "\n",
    "inception_transfer.add(Dense(7 , activation='softmax'))\n",
    "\n",
    "inception_transfer.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bf9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_transfer_hist = inception_transfer.fit(train_data, epochs=15, validation_data=valid_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(inception_transfer_hist, 'Convultional Neural Network with InceptionV3 Transfer Learning', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = inception_transfer.evaluate(train_data, verbose=1)\n",
    "valid_loss, valid_acc = inception_transfer.evaluate(valid_data, verbose=1)\n",
    "\n",
    "print(f'\\n\\nTraining Accuracy:\\t{train_acc * 100}\\nTraining Loss:\\t\\t{train_loss}\\n')\n",
    "print(f'Validation Accuracy:\\t{valid_acc * 100}\\nValidation Loss:\\t{valid_loss}\\n')\n",
    "print('Train/Validation Diff:\\t', np.abs(train_acc - valid_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(inception_transfer, open('inception_transfer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42532a39",
   "metadata": {},
   "source": [
    "Using ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc3620",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50 = ResNet50(weights='imagenet', include_top=False, input_shape=None)\n",
    "\n",
    "for layer in resnet_50.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0fd4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_transfer = Sequential()\n",
    "\n",
    "resnet_transfer.add(data_augmentation)\n",
    "\n",
    "resnet_transfer.add(resnet_50)\n",
    "\n",
    "resnet_transfer.add(GlobalAveragePooling2D())\n",
    "\n",
    "resnet_transfer.add(Dense(200 , activation ='relu'))\n",
    "resnet_transfer.add(BatchNormalization())\n",
    "resnet_transfer.add(Dense(100 , activation ='relu'))\n",
    "resnet_transfer.add(BatchNormalization())\n",
    "resnet_transfer.add(Dense(100 , activation ='relu'))\n",
    "resnet_transfer.add(BatchNormalization())\n",
    "\n",
    "resnet_transfer.add(Dense(7 , activation='softmax'))\n",
    "\n",
    "resnet_transfer.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_transfer_hist = resnet_transfer.fit(train_data, epochs=15, validation_data=valid_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(resnet_transfer_hist, 'Convultional Neural Network with ResNet50 Transfer Learning', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88121cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = resnet_transfer.evaluate(train_data, verbose=1)\n",
    "valid_loss, valid_acc = resnet_transfer.evaluate(valid_data, verbose=1)\n",
    "\n",
    "print(f'\\n\\nTraining Accuracy:\\t{train_acc * 100}\\nTraining Loss:\\t\\t{train_loss}\\n')\n",
    "print(f'Validation Accuracy:\\t{valid_acc * 100}\\nValidation Loss:\\t{valid_loss}\\n')\n",
    "print('Train/Validation Diff:\\t', np.abs(train_acc - valid_acc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f536e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(resnet_transfer, open('resnet_transfer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee45ae5",
   "metadata": {},
   "source": [
    "##### Chosen Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d63b37f",
   "metadata": {},
   "source": [
    "From all the models that were testted above, the best model in terms of highest accuracy and least loss and overfit, is the `VGG19` transfer learning model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
